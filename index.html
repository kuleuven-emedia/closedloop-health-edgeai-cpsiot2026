<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Closing the Loop in Multimodal Edge AI for Healthcare">
  <meta name="description" content="A half-day hands-on tutorial session accelerating the development of real-time closed-loop distributed sensing and edge AI processing systems in smart healthcare applications, continuous at-home and free-living monitoring, and intelligent powered assisted mobility devices, using the HERMES framework">
  <meta name="keywords" content="realtime, multimodal, edge AI, healthcare, assisted devices, machine learning, distributed sensing, wearable sensors, exoskeleton, prosthesis">
  <meta name="author" content="Maxim Yudayev, Jona Beysens, Louis Flynn">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="e-Media Research Lab @ KU Leuven">
  <meta property="og:title" content="Closing the Loop in Multimodal Edge AI for Healthcare">
  <meta property="og:description" content="A half-day hands-on tutorial session accelerating the development of real-time closed-loop distributed sensing and edge AI processing systems in smart healthcare applications, continuous at-home and free-living monitoring, and intelligent powered assisted mobility devices, using the HERMES framework">
  <meta property="og:url" content="https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026">
  <meta property="og:image" content="https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026/static/images/social_preview.jpg">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Closing the Loop in Multimodal Edge AI for Healthcare - Research Preview">
  <meta property="article:published_time" content="2026-01-05T00:00:00.000Z">
  <meta property="article:author" content="Maxim Yudayev">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="realtime">
  <meta property="article:tag" content="multimodal">
  <meta property="article:tag" content="edge AI">
  <meta property="article:tag" content="healthcare">
  <meta property="article:tag" content="assisted devices">
  <meta property="article:tag" content="machine learning">
  <meta property="article:tag" content="distributed sensing">
  <meta property="article:tag" content="wearable sensors">
  <meta property="article:tag" content="exoskeleton">
  <meta property="article:tag" content="prosthesis">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@eMediaResearch">
  <meta name="twitter:creator" content="@MaximYudayev">
  <meta name="twitter:title" content="Closing the Loop in Multimodal Edge AI for Healthcare">
  <meta name="twitter:description" content="A half-day hands-on tutorial session accelerating the development of real-time closed-loop distributed sensing and edge AI processing systems in smart healthcare applications, continuous at-home and free-living monitoring, and intelligent powered assisted mobility devices, using the HERMES framework">
  <meta name="twitter:image" content="https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026/static/images/social_preview.jpg">
  <meta name="twitter:image:alt" content="Closing the Loop in Multimodal Edge AI for Healthcare - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Closing the Loop in Multimodal Edge AI for Healthcare">
  <meta name="citation_author" content="Yudayev, Maxim">
  <meta name="citation_author" content="Beysens, Jona">
  <meta name="citation_author" content="Flynn, Louis">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="CPS-IoT Week">
  <meta name="citation_pdf_url" content="https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026/static/pdfs/summary.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>Closing the Loop in Multimodal Edge AI for Healthcare | Tutorial Session</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" id="favicon" type="image/x-icon" href="static/images/favicon.svg">
  <link rel="apple-touch-icon" id="favicon-apple" href="static/images/favicon.svg">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Closing the Loop in Multimodal Edge AI for Healthcare",
    "description": "A half-day hands-on tutorial session accelerating the development of real-time closed-loop distributed sensing and edge AI processing systems in smart healthcare applications, continuous at-home and free-living monitoring, and intelligent powered assisted mobility devices, using the HERMES framework",
    "author": [
      {
        "@type": "Person",
        "name": "Maxim Yudayev",
        "affiliation": {
          "@type": "Organization",
          "name": "KU Leuven"
        }
      },
      {
        "@type": "Person",
        "name": "Jona Beysens",
        "affiliation": {
          "@type": "Organization",
          "name": "KU Leuven"
        }
      }
      {
        "@type": "Person",
        "name": "Louis Flynn",
        "affiliation": {
          "@type": "Organization",
          "name": "Vrije Universiteit Brussel"
        }
      }
    ],
    "datePublished": "2026-01-05T00:00:00.000Z",
    "publisher": {
      "@type": "Organization",
      "name": "CPS-IoT Week 2026"
    },
    "url": "https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026",
    "image": "https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026/static/images/social_preview.jpg",
    "keywords": ["realtime", "multimodal", "edge AI", "healthcare", "assisted devices", "machine learning", "distributed sensing", "wearable sensors", "exoskeleton", "prosthesis"],
    "abstract": "In this interactive half-day tutorial, we will teach the use of a new developer-friendly framework for end-to-end edge AI system design and deployment to the wider CPS/IoT audience, using a visually entertaining use case of assisted mobility devices (lower-body exoskeleton or a leg prosthesis). The participants will gain practical experience and an intuition for balancing design decisions of real-time distributed multimodal edge AI and AIoT (Artificial Intelligence of Things) sensing systems. The session will cover real-world relevant components - multimodal distributed sensing and high-quality dataset curation, data fusion and streaming multimodal inference strategies, hardware-aware embedding of AI. The guided hands-on part of the session will help participants pass the learning curve of adapting the framework with new sensing, actuation, and AI processing functionality, and integrating it with the streamlined AI workflows and toolchains. At the end of the tutorial, participants will (1) have a more cohesive view on the end-to-end edge AI system development, (2) know how to accelerate their prototyping efforts using HERMES [https://github.com/maximyudayev/hermes], (3) have a locally-run tool for curation of high-quality multimodal datasets.",
    "citation": "@misc{multimodaledgeai-tutorial-cpsiot2026,
  author       = {Yudayev, Maxim and Beysens, Jona and Flynn, Louis},
  title        = {Closing the Loop in Multimodal Edge {AI} for Healthcare},
  howpublished = {Tutorial at CPS-IoT Week},
  month        = may,
  year         = {2026},
  address      = {Saint-Malo, France},
  note         = {Presented May 11--14, 2026}
}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://kuleuven-emedia.github.io/closedloop-health-edgeai-cpsiot2026"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Intellgient healthcare applications"
      },
      {
        "@type": "Thing",
        "name": "Realtime assisted mobility devices"
      },
      {
        "@type": "Thing", 
        "name": "Continuous wearable and off-body monitoring systems"
      },
      {
        "@type": "Thing", 
        "name": "In-lab and free-living distributed physiological sensing"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "e-Media Research Lab @ KU Leuven",
    "url": "https://iiw.kuleuven.be/onderzoek/emedia",
    "logo": "https://raw.githubusercontent.com/kuleuven-emedia/.github/refs/heads/main/resources/logo.svg",
    "sameAs": [
      "https://github.com/kuleuven-emedia",
      "https://www.linkedin.com/company/emediaresearch",
      "https://twitter.com/eMediaResearch",
      "https://x.com/eMediaResearch",
    ]
  }
  </script>

  <!-- Auto dark/light mode switching favicon -->
  <script>
    const isDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
    const favicon = document.getElementById('favicon');
    const favicon_apple = document.getElementById('favicon');
    favicon.href = isDark ? 'static/images/favicon_dark.svg' : 'static/images/favicon.svg';
    favicon_apple.href = isDark ? 'static/images/favicon_dark.svg' : 'static/images/favicon.svg';
  </script>
</head>
<body>


  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <!-- Banner -->
  <main id="main-content">
  <section class="hero custom-background">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Closing the Loop in Multimodal Edge AI for Healthcare</h1>
            <div class="is-size-4 subtitle-block">Accelerating the development of realtime closed-loop systems</div>
            <div class="is-size-5 event-block">
              Half-day Hands-on Tutorial Session at the  
              <a href="https://cps-iot-week2026.inria.fr/" target="_blank">ACM/IEEE CPS-IoT Week 2026</a>
            </div>
            <div class="is-size-5 venue-block">
              May 11-14, 2026 (<a href="https://www.pgl-congres.com/en/" target="_blank">Palais des Congr√®s de Saint Malo</a> - Saint-Malo, France)
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://forms.cloud.microsoft/e/WAnmM8y0tv" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 640">
                        <path fill="white" d="M424 64C437.3 64 448 74.7 448 88L448 128L480 128C515.3 128 544 156.7 544 192L544 480C544 515.3 515.3 544 480 544L160 544C124.7 544 96 515.3 96 480L96 192C96 156.7 124.7 128 160 128L192 128L192 88C192 74.7 202.7 64 216 64C229.3 64 240 74.7 240 88L240 128L400 128L400 88C400 74.7 410.7 64 424 64zM160 176C151.2 176 144 183.2 144 192L144 480C144 488.8 151.2 496 160 496L480 496C488.8 496 496 488.8 496 480L496 192C496 183.2 488.8 176 480 176L160 176zM390.7 241.9C398.5 231.2 413.5 228.8 424.2 236.6C434.9 244.4 437.3 259.4 429.5 270.1L307.4 438.1C303.3 443.8 296.9 447.4 289.9 447.9C282.9 448.4 276 445.9 271.1 441L215.2 385.1C205.8 375.7 205.8 360.5 215.2 351.2C224.6 341.9 239.8 341.8 249.1 351.2L285.1 387.2L390.7 242z"/>
                      </svg>
                    </span>
                    <span>RSVP</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End banner -->


  <!-- Organizers logos -->
  <section class="hero">
    <div class="hero-body hero-logos">
      <div class="institution"><a href="https://iiw.kuleuven.be/onderzoek/emedia" target="_blank"><img src="static/images/kuleuven_logo.png" alt="Logo of the e-Media Research Lab and STADIUS, at KU Leuven"/></a></div>
      <div class="conference"><a href="https://cps-iot-week2026.inria.fr/" target="_blank"><img src="static/images/cpsiotweek2026_logo.png" alt="Logo of the CPS-IoT Week"/></a></div>
      <div class="institution"><a href="https://www.brubotics.eu/" target="_blank"><img src="static/images/brubotics_logo.jpg" alt="Logo of the BruBotics research group, at Vrije Universiteit Brussel"/></a></div>
    </div>
  </section>
  <!-- End organizers logos -->


  <!-- Event abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="has-text-centered">
        <h2 class="title is-3">Abstract</h2>
      </div>
      <div class="content has-text-justified">
        <p>
Diverse R&D use cases - from physiological dataset curation, to continuous monitoring and wearable intervention devices, in fixed labs and in the wild, share in common the need for reliable continuous multimodal sensing and realtime processing at the edge.
These multimodal signals from distributed sensors encapsulate rich information about the state of the person and their environment, exceeding the depth of insights represented by a single modality.
However, multiple technical cross-disciplinary challenges inhibit the efforts of researchers in their core objectives.
By streamlining the system design flow and leveraging reusable extensible community-driven frameworks, we can accelerate the process of developing novel edge AI and sensing systems for transformative healthcare applications.

In this interactive half-day tutorial, we will teach the use of a new developer-friendly framework for end-to-end edge AI system design and deployment to the wider CPS/IoT audience, using a visually entertaining use case of assisted mobility devices (lower-body exoskeleton or a leg prosthesis).
The participants will gain practical experience and an intuition for balancing design decisions of real-time distributed multimodal edge AI and AIoT sensing systems.
The session will cover real-world relevant components - multimodal distributed sensing and high-quality dataset curation, data fusion and streaming multimodal inference strategies, hardware-aware embedding of AI.
The guided hands-on part of the session will help participants pass the learning curve of adapting the framework with new sensing, actuation, and AI processing functionality, and integrating it with the streamlined AI workflows and toolchains.
At the end of the tutorial, participants will (1) have a more cohesive view on the end-to-end edge AI system development, (2) know how to accelerate their prototyping efforts using <a href="https://maximyudayev.github.io/hermes/" target="_blank">HERMES</a>, (3) have a locally-run tool for curation of high-quality multimodal datasets.
        </p>
        <p>
          <img src="static/images/closed_loop.png" alt="Overview of an intelligent assisted mobility device usecase, showing the continuous closed-loop operation of the system between sensing, realtime processing and intervention" class="center-image blend-img-background" loading="lazy">
        </p>
      </div>
    </div>
  </section>
  <!-- End event abstract -->


  <!-- Schedule -->
  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="content">
            <div class="has-text-centered">
              <h2 class="title is-3">Tutorial Schedule</h2>
            </div>
            <div class="content has-text-justified schedule">
              <p>
                <strong>Date:</strong>
                May [TBA], 2026 (9:00 - 13:00 CET)
              </p>
              <p>
                <strong>Tutorial duration:</strong>
                240 min
              </p>
              <p>
                <strong>Tutorial's type:</strong>
                lecture style + interactive hands-on + collaborative demo
              </p>
              <ul>
                <li>
                  <strong>Welcome and introduction</strong>
                  (15 min)
                  <ul>
                    <li>
                      Introduction of end-to-end edge AI pipelines and motivation of the tutorial (5 min)
                    </li>
                    <li>
                      Introduction of the <a href="https://maximyudayev.github.io/hermes/" target="_blank">HERMES</a> framework as a prototyping accelerator (7 min)
                    </li>
                    <li>
                      Tutorial's overview (3 min)
                    </li>
                  </ul>
                </li>
                <li>
                  <strong>Multimodal data fusion</strong>
                  (30 min)
                  <ul>
                    <li>
                      Key design knobs of practical realtime multimodal systems
                      <ul>
                        <li>Sources of latency</li>
                        <li>Inference strategies</li>
                        <li>Latency and forecasting horizon</li>
                        <li>Temoral resolution of predictions</li>
                      </ul>
                    </li>
                    <li>
                      Trade-offs and design intuition
                      <ul>
                        <li>Balancing latency and prediction horizon</li>
                        <li>Relaxing inference time budget</li>
                        <li>Impact of model adaptations</li>
                      </ul>
                    </li>
                  </ul>
                </li>
                <li>
                  <strong>Design closed-loop system</strong>
                  (90 min)
                  <ul>
                    <li>Exoskeleton / prosthesis usecase context, objectives and constraints</li>
                    <li>[Hands-on]: Extend HERMES to support a new integrated sensor</li>
                    <li>[Demo]: Small-scale multimodal data collection with the system</li>
                    <li>[Follow-along]: Analysis of resource utilization, and signals</li>
                    <li>[Follow-along]: Iterative constraint-driven AI model design</li>
                  </ul>
                </li>
                <li>
                  <strong>Break + QA</strong>
                  (15 min)
                </li>
                <li>
                  <strong>Realtime demonstration</strong>
                  (60 min)
                  <ul>
                    <li>[Hands-on]: Inject pretrained AI model in a closed-loop HERMES system</li>
                    <li>[Hands-on]: Deploy application onto embedded hardware</li>
                    <li>[Demo]: Validate the realtime system by piloting the device</li>
                  </ul>
                </li>
                <li>
                  <strong>Future directions</strong>
                  (30 min)
                  <ul>
                    <li>Concluding remarks</li>
                    <li>Open challenges</li>
                    <li>Call for collaborations</li>
                    <li>Q&A</li>
                  </ul>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End schedule -->


  <!-- Materials -->
  <section class="section hero is-small is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="content">
            <h2 class="title is-3">Useful Materials</h2>
            <p>
              <strong>HERMES documentation:</strong>
              <a href="https://maximyudayev.github.io/hermes/" target="_blank">[url]</a>
            </p>
            <p>
              <strong>Slides:</strong>
              [TBA]
            </p>
            <p>
              <strong>Hands-on:</strong>
              [TBA]
            </p>
            <p>
              <strong>Recording:</strong>
              [TBA] (after event)
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Organizers -->
  <section class="section hero is-small">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full">
          <div class="content">
            <div class="has-text-centered">
              <h2 class="title is-3">Organizers</h2>
            </div>

            <div class="level-set">
              <div class="is-size-5"><strong>Maxim Yudayev</strong></div>
              <p>Email: <a href="mailto:maxim.yudayev@kuleuven.be?subject=[CPS-IoT 2026] Tutorial session question">maxim.yudayev@kuleuven.be</a></p>
              <p>Website: <a href="https://yudayev.com" target="_blank">https://yudayev.com</a></p>
            </div>
            <div class="columns">
              <div class="column is-one-fifth valign">
                <img src="static/images/maxim.jpg" loading="lazy">
              </div>
              <div class="column">
                <p>
                  Maxim is a graduating PhD in the team of Prof. Bart Vanrumste at the e-Media Research Lab of KU Leuven in Belgium.
                  He develops novel software and hardware edge AI technologies that enable real-time distributed sensing and continuous multimodal processing of sensor data for intelligent ambient healthcare applications.
                  Prior to KU Leuven, Maxim worked at the Nokia Bell Labs research centre in Antwerp, Belgium, where he patented a look-ahead computation hardware mechanism for efficient and energy-preserving AI computer architectures.
                  With domain expertise in digital design, networks, electronics, distributed parallel software, and embedded systems, he focuses on delivering practical solutions from the systems-level perspective to meet complex R&D challenges.
                </p>
              </div>
            </div>
            
            <div class="level-set">
              <div class="is-size-5"><strong>Jona Beysens</strong></div>
              <p>Email: <a href="mailto:jona.beysens@kuleuven.be">jona.beysens@kuleuven.be</a></p>
              <p>Website: <a href="https://jonabeysens.github.io" target="_blank">https://jonabeysens.github.io</a></p>
            </div>
            <div class="columns">
              <div class="column is-one-fifth valign">
                <img src="static/images/jona.jpg" loading="lazy">
              </div>
              <div class="column">
                <p>
                  Jona is an Assistant Professor in the e-Media Research Lab at KU Leuven.
                  His research interests include tinyML and wireless networking, with a focus on designing hardware-aware AI algorithms tailored to low-power embedded systems for innovative healthcare applications.
                  Prior to KU Leuven, he was a Senior R&D Engineer at CSEM in Switzerland, where he led several national and international (EU) tinyML-related research projects.
                  He obtained a PhD from KU Leuven in 2020 on Robust Visible Light Communication Networks (LiFi).
                  With his team at CSEM, he won the first prize of the international tinyML Smart Weather Station Challenge 2022, where they built an acoustic weather station powered by embedded AI.
                  During his time at CSEM, he was a member of the Swiss EdgeAI Foundation branch, consisting of members from both Swiss industry and academia.
                </p>
              </div>
            </div>

            <div class="level-set">
              <div class="is-size-5"><strong>Louis Flynn</strong></div>
              <p>Email: <a href="mailto:louis.flynn@vub.be">louis.flynn@vub.be</a></p>
              <p>Website: <a href="https://researchportal.vub.be/en/persons/louis-flynn" target="_blank">https://researchportal.vub.be/en/persons/louis-flynn</a></p>
            </div>
            <div class="columns">
              <div class="column is-one-fifth valign">
                <img src="static/images/louis.jpg" loading="lazy">
              </div>
              <div class="column">
                <p>
                  Louis is a leading postdoctoral researcher in human-robot interaction and rehabilitation robotics at the Robotics & Multibody Mechanics (R&MM) and BruBotics research groups of Vrije Universiteit Brussel (VUB) in Belgium.
                  His work focuses on the mechatronic design and advanced control of lower-limb assistive technologies, including active prostheses (like the CYBERLEG X-Leg) and exoskeletons.
                  Dr. Flynn is a key contributor to the design of adaptive controllers that use human-in-the-loop optimization (HILO) strategies to personalize robotic assistance of intelligent mobility devices, reduce user effort, and maximize functional ability of the wearer.
                  His research is dedicated to translating compliant actuation and bio-inspired robotics into safe, energy-efficient, and user-accommodating devices for real-world impact.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End schedule -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@misc{multimodaledgeai-tutorial-cpsiot2026,
  author       = {Yudayev, Maxim and Beysens, Jona and Flynn, Louis},
  title        = {Closing the Loop in Multimodal Edge {AI} for Healthcare},
  howpublished = {Tutorial at CPS-IoT Week},
  month        = may,
  year         = {2026},
  address      = {Saint-Malo, France},
  note         = {Presented May 11--14, 2026}
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </p>
            <p>
              This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

  </body>
</html>
